{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 將Fliter個數做調整\n",
    "### 將learning rate改為0.08\n",
    "### 試試其中一個fliter改成1*1\n",
    "### 訓練次數增加\n",
    "### 神經元個數修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interact_manual\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料總筆數為60000筆資料\n",
      "測試資料總筆數為10000筆資料\n"
     ]
    }
   ],
   "source": [
    "print(f'訓練資料總筆數為{len(x_train)}筆資料',f'測試資料總筆數為{len(x_test)}筆資料',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    0:'T-shirt/top',\n",
    "    1:'Trouser',\n",
    "    2:'Pullover',\n",
    "    3:'Dress',\n",
    "    4:'Coat',\n",
    "    5:'Sandal',\n",
    "    6:'Shirt',\n",
    "    7:'Sneaker',\n",
    "    8:'Bag',\n",
    "    9:'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3037ff5580834e0486622f993ccac556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='訓練編號', max=59999), Button(description='Run Interact', st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_xy(訓練編號=0):\n",
    "    ax = plt.gca()\n",
    "    X = x_train[訓練編號]\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    plt.imshow(X,cmap='Greys')\n",
    "    print(f'該資料 y 給定的答案為: {labels[y_train[訓練編號]]}')\n",
    "interact_manual(show_xy,訓練編號=(0,59999));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 要注意一張圖有多少個 channel, 開始我們因為只有灰階, 所以只有一個 channel。因此我們要轉一下我們的資料格式:\n",
    "# (28,28) --> (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1) / 255\n",
    "x_test = x_test.reshape(10000, 28, 28, 1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[87].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\huhu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(16, (3,3), padding='same',\n",
    "                input_shape=(28,28,1),\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出 16 個 28x28 矩陣\n",
    "# 事實上是 (28, 28, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (14,14,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(48, (1,1), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output (14, 14, 48) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output (7, 7, 48) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(96, (3,3), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output (7, 7, 96) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output (3, 3, 96) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(150, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 48)        816       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 96)          41568     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 150)               129750    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 173,804\n",
      "Trainable params: 173,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3*3 (權重) + 1 (bias)]*16個filters = 160\n",
      "[1*1(權重)*16個channels + 1 (bias)]*48個filters = 816\n",
      "[3*3(權重)*48個channels + 1 (bias)]*96個filters = 41568\n",
      "Flatten = 864\n",
      "dense = 129600\n"
     ]
    }
   ],
   "source": [
    "print('[3*3 (權重) + 1 (bias)]*16個filters =',(3*3+1)*16)\n",
    "\n",
    "print('[1*1(權重)*16個channels + 1 (bias)]*48個filters =',(1*1*16+1)*48)\n",
    "\n",
    "print('[3*3(權重)*48個channels + 1 (bias)]*96個filters =',(3*3*48+1)*96)\n",
    "\n",
    "print('Flatten =',3*3*96)\n",
    "\n",
    "print('dense =',864*150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.08),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 34s 560us/sample - loss: 0.0894 - acc: 0.2682\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 36s 603us/sample - loss: 0.0881 - acc: 0.3891\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 36s 604us/sample - loss: 0.0839 - acc: 0.4021\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 36s 606us/sample - loss: 0.0600 - acc: 0.5823\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 36s 607us/sample - loss: 0.0422 - acc: 0.6976\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 37s 611us/sample - loss: 0.0376 - acc: 0.7319\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 37s 612us/sample - loss: 0.0355 - acc: 0.7497\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 37s 612us/sample - loss: 0.0339 - acc: 0.7606\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 37s 615us/sample - loss: 0.0327 - acc: 0.7683\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 37s 615us/sample - loss: 0.0318 - acc: 0.7742\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 37s 615us/sample - loss: 0.0308 - acc: 0.7817\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 37s 622us/sample - loss: 0.0300 - acc: 0.7873\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 37s 616us/sample - loss: 0.0292 - acc: 0.7928\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 37s 614us/sample - loss: 0.0286 - acc: 0.7990\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 37s 615us/sample - loss: 0.0280 - acc: 0.8029\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 37s 617us/sample - loss: 0.0274 - acc: 0.8073\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 37s 618us/sample - loss: 0.0270 - acc: 0.8127\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 37s 621us/sample - loss: 0.0263 - acc: 0.8160\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 37s 624us/sample - loss: 0.0259 - acc: 0.8188\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 38s 625us/sample - loss: 0.0254 - acc: 0.8236\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 38s 629us/sample - loss: 0.0249 - acc: 0.8268\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 38s 630us/sample - loss: 0.0245 - acc: 0.8297\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 38s 632us/sample - loss: 0.0241 - acc: 0.8328\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 38s 634us/sample - loss: 0.0238 - acc: 0.8356\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 38s 631us/sample - loss: 0.0233 - acc: 0.8386\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 38s 628us/sample - loss: 0.0230 - acc: 0.8400\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 38s 631us/sample - loss: 0.0228 - acc: 0.8418\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 38s 634us/sample - loss: 0.0224 - acc: 0.8451\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 38s 638us/sample - loss: 0.0222 - acc: 0.8464\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 38s 635us/sample - loss: 0.0219 - acc: 0.8495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19ffc2eaac8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03daed104864df7b9cde014dbc1bdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='測試編號', max=9999), Button(description='Run Interact', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_xy(測試編號=0):\n",
    "    ax = plt.gca()\n",
    "    X = x_test[測試編號]\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    plt.imshow(x_test[測試編號].reshape(28,28),cmap='Greys')\n",
    "    print(f'神經網路預測的答案為: {labels[result[測試編號]]}')\n",
    "interact_manual(show_xy,測試編號=(0,9999));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 216us/sample - loss: 0.0237 - acc: 0.8364\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的正確率為 0.8364\n"
     ]
    }
   ],
   "source": [
    "print('測試資料的正確率為', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經網路預測是: T-shirt/top\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19f9aa59b88>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=7778\n",
    "print('神經網路預測是:',labels[result[n]])\n",
    "plt.imshow(x_test[n].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
